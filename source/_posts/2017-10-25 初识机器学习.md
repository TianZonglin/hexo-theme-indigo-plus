date: 2017-10-25
categories: ML学习笔记
tags: [机器学习, 笔记]
comments: true
title: 初识机器学习
---

## **几个基础算法**

### 关联规则
> 啤酒和尿布的案例
原始的购物篮分析，属于数据挖掘范畴，但也是机器学习的必备算法。

### 协同过滤
> 高级的购物篮分析，是推荐系统常用到的算法之一

### 聚类
> 运营商人群分类案例
通过聚类分离不同人群，然后再分析人群的特点，制定不同的品牌，其属于机器学习范畴，对于给定的数据，运行给定的算法即可获得相关结果

### 朴素贝叶斯
> 原始的垃圾邮件过滤经常被用到

### 决策树
> 通过不同的参数指标来获得对事物的评判

### CTR预估
> 类似于PageRank的目的，其对指定对象进行评分排名


## **机器学习和数据分析的区别**

### **处理数据的不同**
> 机器学习：处理行为数据，搜索记录，浏览记录，评论记录等等
数据分析：处理交易数据，账单工单等等
数据量：海量/行为数据 VS  交易/少量数据

### **数据特点不同**
> 交易数据的一致性要求非常高，事务保证，确保数据一致性
行为数据一致性不高，数据缺失影响不大，对于整体分析结果影响较少
>对于交易型数据的存储：关系型数据库
>行为数据：MongoDB等NoSQL数据库

- 对于数据一致性不高的特点：产生了NoSQL
- NoSQL特点：保证数据吞吐量的前提下会损失一致性，所以存储上：

### **分析方法不同**
> 数据分析多采用采样分析
机器学习大多是全量分析，数据量越多，分析结果越贴合


### **解决的问题不一样**
> 过去的历史数据特点：数据分析
> 预测未来的用户特点：机器学习

### **技术手段不同**
| 分类 | 特点 |
| --------   | -----:  | 
|数据分析|汇总数据，OLAP，纬度少，属性少，数据量小，用户驱动，交互式分析
|机器学习|明细全量数据，纬度多，属性多，数据量大，数据驱动，自动进行知识发现

### **参与者、受众不同**
>数据分析取决于分析师的能力视角，目标用户是特定决策者
机器学习结果：取决于数据质量，数据驱动，算法影响较小，目标用户是数据用户本身

## **机器学习算法分类**

| 依据|类别|
| --- |--- | ---
| 按训练数据特点|有监督学习，无监督学习，半监督学习|
| 按算法解决的问题|分类和回归，聚类，标注|
| 按算法本质|生成模型，判别模型|

### **按训练数据特点**
对样本数据进行训练，得到一个模型，然后判断Y(输出)-X(输入)关系

 1. 有监督学习：分类算法(类别)、回归算法(数字)
>例如分类垃圾邮件：
训练数据明确给出每个样本属于哪个类别，已经打好标签
特点，垃圾邮件已知，通过训练获得垃圾邮件的特征，从而分类出垃圾邮件
>评判：给出垃圾邮件，要分到垃圾类别
 2. 无监督学习：不知道类别，标签未知，数据中没有Y
>例如用户聚类：
分类之前不知道具体类别，算法结束后才知道具体类别和类别特征
 3. 半监督学习、强化学习
>可能开始有Y值，但是模型结果不好，但随着训练增多结果变好

### **按算法解决问题**
 1. 分类和回归：预测分类，预测Y值
 2. 聚类
 3. 标注：例如文本，可以切词，打标签，标注算法
 
### **按算法的本质**
 1. 生成模型：告诉属于各个类的概率，模棱两可，陪审团
 2. 判别模型：直接给算法，数据丢进去返回哪一类，非黑即白，法庭宣判
>通常用来说分类问题
例如逻辑回归和朴素贝叶斯的本质区别：是判别和生成模型的区别
从算法实现思想出发，非常重要！

## **常见算法**
|类别|名称|特点|
| --- |--- | --- |
|分类|C4.5|有监督算法，淘汰|
|聚类|K-Means|无监督算法
|分类|SVM|基于统计，有数学理论支撑（效果好，有理论支撑）-被深度学取代-必考，公式推导
|关联分析|Apriori|频繁项集挖掘，代价大，被FP-Growth取代，只需；两次扫描数据库，推荐不用这些算法了
|抽象|EM|算法框架，K-Means本质即为EM算法
|链接|PageRank||
|分类框体|AdaBoost|人脸识别，有监督学习
|分类|kNN|最简单，有监督学习，类似k-means
|分类|NativeBayes||
|分类|CART|淘汰|
其他杂类

|名称|特点|
| --- |--- | 
|FP-Growth|频繁项集挖掘   
|逻辑回归|搜索结果排序，本质逻辑回归
|RF随机森林、GBDT|类似AdaBoost，都是决策树算法改进
|推荐算法|—
|LDA|文本分析，自然语言处理   难度大
|Word2Vector|文本挖掘
|HMM马尔科夫模型、CRF条件随机场|文本挖掘
|深度学习系列算法|—

## **机器学习的框架**
机器学习解决的问题无非两类：预测、分类
预测：预测所属分类、预测预测数值，区别：预测目标Y是连续的还是离散的

### **算法概要流程**

#### **准备工作**
 1. 首先确定业务需求，确定问题
 2. 围绕问题收集数据
 3. 特征工程：预处理、提取特征，清洗整合重构，ETL过程，时间占比七成左右
>例如预测购买力，要确定收入、学历等数据，筛选出来结构化
如果数据准备好了，那么用哪种模型对结果效果影响较小，特征工程的影响非常大
数据的好坏基本会决定了整个学习的效果。

#### **训练模型**
 4. 针对问题定义模型
>定义模型的参数是不知道的，通过训练数据求参数，最终产生一个公式
 5. 定义损失函数
>评估偏差的大小，机器学习没法得到问题的解析解/精确解，找到偏差最小的函数
偏差的定义：对于回归问题就是真实与预测的查，对于分类问题偏差定义较困难不直观，必须用数学方式定义之。loglogth，thinge等等
 6. 优化算法
>在定义损失函数之后，确定损失函数的最小值，往往演变为优化问题，又会用到一些优化算法，纯数学问题：凸优化问题、优化问题，涉及梯度下降、随机梯度下降、坐标法等等

#### **模型评估（在输入数据、计算、得到模型之后）**
 1. 交叉验证：K值实值等等
 2. 效果评估指标：准确率，召回率，方差，ROC曲线，AOC等等
>检验模型好不好的标准
 难度：损失函数，优化算法

#### **示例：将图像按颜色分类**
>确定问题：按颜色分类
收集数据：大量图片文件
特征工程：对于图片要根据图像内容，每个像素点由三数字组成；图片大小不一样，即数据维度不一样，如何将图片文件转换为聚类格式，转换为统一维度的向量
训练模型：K-Mean聚类
评价指标：暂略
注意：每次结果可能不一致
