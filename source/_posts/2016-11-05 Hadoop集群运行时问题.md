date: 2016-11-05
categories: Hadoop相关
tags: [Hadoop,集群,调试]
comments: true
title: Hadoop集群运行时问题
---

#### Hadoop Copy
>-copyFromLocal 相当于复制
-moveFromLocal 本地会删除，相当于剪切
-getmerge 合并， 源目录 -> 目的目录
-mkdir
-rmr
-ls
-copyToLocal 从hadoop下文件，不过通常用 -get（类似于-put）
hadoop fs -lsr

#### 运行hadoop实例的顺序
>首先，开启hadoop	start-all.sh
之后，创建用户目录  hdfs dfs -mkdir input
之后，构造程序输入  hdfs dfs -put ./etc/hadoop/*.xml input
之后，确认输入有内容  hdfs dfs -ls input
之后，运行jar包  hadoop jar  /etc/local/hadoop/etc/.../example-2.7.3 input output '[a-z.]+'
之后，会输出运行的INFO
之后，cat output 看结果，可以选择取回本地
完成

#### hadoop集群节点不全开
有hadoop01-04 四个节点，现在只开hadoop01，只用master
修改master节点的   /etc/local/hadoop/etc/hadoop/slaves文件
将hadoop01加入，即之前没有hadoop01，表明master节点只有namenode，没有datanode，
现在将datanode让之启动，就可以使master有双重身份
其他配置，其他节点的配置，均不改
以上类似伪分布式，但是更灵活，本身为完全分布式状态，只运行hadoop01时即为节点缺省状态，当其他节点运行时，不用任何改动即可以成为一个集群。
完。


#### IDEA报错详解
```
Cannot delete /tmp/hadoop-yarn/staging/hadoop/.staging/job_1477796535608_0001. 
Name node is in safe mode.
    
原因：Linux集群中的namenode没有关闭safemode
```
```
2016-11-01 18:32:27,979 INFO  [main] mapred.ClientServiceDelegate (ClientServiceDelegate.java:getProxy(276)) - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
Retrying connect to server: 192.168.146.130/192.168.146.130:10020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
Exception in thread "main" java.io.IOException: java.net.ConnectException: Call From MSI/118.202.43.35 to 192.168.146.130:10020 failed on connection exception: java.net.ConnectException: Connection refused: no further information; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused

原因：开启historyserver服务  mr-jobhistory-daemon.sh start historyserver
```

```
问题出现：使用IDEA运行完分词程序后，在输出界面输出了分词信息；
但是去Linux集群下，quer使用find / -name 'output' 却找不到这个文件，

原因：hdfs不是一个实际的路径，如果程序中的代码为
"hdfs://192.168.146.130:9000/tmp/input"
"hdfs://192.168.146.130:9000/tmp/output"
那么实际上在master节点上并没有一个tmp文件夹里存放这两个文件
```
如何将此二文件取回本地，也就是能够实际的打开相应的文件？
```
使用hdfs dfs -get 【hdfs的目录】 【本地目录】
以上命令即可将hdfs上的文件取回本地

如何新建hdfs上的文件，也就是在运行程序的时候需要上传程序的输入到hdfs上

使用hdfs dfs -mkdir 【hdfs新建的目录】
使用hdfs dfs -put 【本地目录】 【hdfs的目录】
以上即可完成hdfs文件的上传
```